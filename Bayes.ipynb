{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes & Guassian Distribution\n",
    "=============================\n",
    "\n",
    "* Bayes \n",
    "-----------------------------------\n",
    "Object: Estimate the Posterior Probability $P(c\\mid X)$\n",
    "+ Discriminative models: modeling $P(c\\mid X)$ directly\n",
    "+ Generative models: modeling $P(X,c)$, then get $P(c\\mid X)$ by Bayes' Theorem:\n",
    "$$ P(c\\mid X)=\\frac{P(c)\\ P(X\\mid c)}{P(X)} $$\n",
    "\n",
    "$$ posterior=\\frac{prior\\times likelihood}{evidence} $$\n",
    "\n",
    "Method: Maximun Likelihood Estimation\n",
    "$$ \\hat{\\theta_c}\\ =\\ arg \\max_{\\theta_c}\\sum_{X\\in D_c}logP(X\\mid \\theta_c) $$\n",
    "\n",
    "\n",
    "\n",
    "* Naive Bayes classifier\n",
    "-------------------------------------\n",
    "> Assumptions (strong): independence between the features.\n",
    "\n",
    "$$ P(c\\mid X)=\\frac{P(c)\\ P(X\\mid c)}{P(X)}=\\frac{P(c)}{P(X)}\\prod_{i=1}^{d}P(x_i\\mid c) $$\n",
    "\n",
    "$$ h_{nb}(X)=\\ arg \\max \\prod_{i=1}^{d} P(x_i\\mid c) $$\n",
    "\n",
    "\n",
    "-----------------------------------\n",
    "* Guassian distribution\n",
    "---------------------\n",
    "+ Math :\n",
    "$x\\sim N(\\mu,\\sigma^2)$\n",
    "+ Alg :\n",
    "Use training Set: $\\left \\{ x_1, x_2, \\cdots, x_n \\right \\}$ to etismate $\\mu$, and $\\sigma$. Then predict the probability of new data by Guassian model.\n",
    "\n",
    "\n",
    "+ Tips:\n",
    "(from Machine Learning Video)\n",
    "    1. Anomaly detection VS supervised algorithms\n",
    "> The number of positive and negative examples are not balanced--> use Guassian model to learn negative distribution. then future anomalies may look nothing like any of the anomalous examples we've seen so far.\n",
    "Positive examples are enough-->use supervised learning. future positive examples likely to be similar to ones in traing set.\n",
    "\n",
    "    2. Data distribution\n",
    "> Non-gaussain features transform to like Gaussian features.   \n",
    "> Transform formula: $log(x+c)$, $sqrt(x)$, $x^\\frac{1}{c}$, etc.  \n",
    "> Use the histgram to see the distribution\n",
    "    \n",
    "\n",
    "* Multivariate Guassian Distribution\n",
    "----------------------------------------\n",
    "> Don't model $p(x_1)$, $p(x_2)$, $\\cdots$, etc. sepatately. Model $p(x)$ all in one go.\n",
    "\n",
    ">--> then we can also model correlations between the data.\n",
    "\n",
    "+ Math\n",
    "> Parameters $\\mu \\in R^n$, $\\Sigma \\in R^{nxn}$.\n",
    "$$ p(x;{\\color{Red}\\mu},{\\color{Red}\\Sigma})= \\frac{1}{(2\\pi)^{\\frac{n}{2}} |\\Sigma|^{\\frac{1}{2}}} exp(-\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1}(x-\\mu))$$\n",
    "\n",
    "+ Alg :\n",
    "> Maximum Likelihood estimates\n",
    "$$ \\hat{\\mu}= \\frac{1}{n}\\sum_{i=1}^{n}x_i$$\n",
    "$$ \\hat{\\Sigma}= \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\hat{\\mu})^T(x_i-\\hat{\\mu}) $$\n",
    "\n",
    "\n",
    "* Ref:\n",
    "--------------------------------\n",
    "+ https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n",
    "+ 机器学习（by 周志华)\n",
    "+ Machine Learning (By Andrew Ng) / anomaly-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
