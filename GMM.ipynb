{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guassian Mixture Model (GMMï¼‰\n",
    "=============================\n",
    "\n",
    "Guassian distribution\n",
    "---------------------\n",
    "$x N(\\mu,\\sigma^2)$\n",
    "\n",
    "\n",
    "* Motivation\n",
    "-------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Tips:\n",
    "---------------------------------------------\n",
    "(from Machine Learning Video)\n",
    "+ Anomaly detection VS supervised algorithms\n",
    "> The number of positive and negative examples are not balanced--> use Guassian model to learn negative distribution. then future anomalies may look nothing like any of the anomalous examples we've seen so far.\n",
    "Positive examples are enough-->use supervised learning. future positive examples likely to be similar to ones in traing set.\n",
    "\n",
    "+ Data distribution\n",
    "> Non-gaussain features --> transform to -->like Gaussian  \n",
    "> such as : $log(x+c)$, $sqrt(x)$, $x^\\frac{1}{c}$\n",
    "> use the histgram to see the distribution\n",
    "\n",
    "\n",
    "* Ref:\n",
    "--------------------------------\n",
    "Machine Learning (By Andrew Ng) / 15_anomaly-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
